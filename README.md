# SWE-RL: Self-Play Software Engineering with Reinforcement Learning

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![arXiv](https://img.shields.io/badge/arXiv-2512.18552-b31b1b.svg)](https://arxiv.org/abs/2512.18552)

An implementation of **Self-play SWE-RL (SSR)** - where AI agents create their own software engineering training tasks and learn to solve them.

---

## ğŸ™ Based on Groundbreaking Research

This project implements concepts from:

> **"SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution"**
>
> **Yuxiang Wei, Olivier Duchenne, Jade Copet, Quentin Carbonneaux, Lingming Zhang, Daniel Fried, Gabriel Synnaeve, Rishabh Singh, Sida I. Wang**
>
> Meta AI (FAIR) â€¢ University of Illinois Urbana-Champaign â€¢ Carnegie Mellon University
>
> ğŸ“„ [Read the paper](https://arxiv.org/abs/2512.18552)

We are deeply grateful to the research team for publishing this innovative work that demonstrates how reinforcement learning on real-world software evolution data can advance LLM reasoning capabilities.

---

## ğŸ¯ What is SSR?

**Self-play SWE-RL** is a paradigm where:

1. An **Injector Agent** creates realistic bugs in working code
2. A **Validator** ensures the bugs are meaningful and solvable
3. A **Solver Agent** attempts to fix the bugs using only test feedback
4. Both agents improve through this self-play loop

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Inject    â”‚ â”€â”€â”€â”€ Creates bug + oracle test
     â”‚    Agent    â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Validate   â”‚ â”€â”€â”€â”€ 7-step verification
     â”‚  (7 steps)  â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Solver    â”‚ â”€â”€â”€â”€ Fixes bug using test only
     â”‚    Agent    â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Reward    â”‚ â”€â”€â”€â”€ +1.0 if solved, 0.0 otherwise
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ ssr-studio/          # Main implementation
â”‚   â”œâ”€â”€ demo.py          # Run a complete episode
â”‚   â”œâ”€â”€ examples/        # Sample project for testing
â”‚   â”œâ”€â”€ src/             # Python backend
â”‚   â””â”€â”€ ui/              # Next.js dashboard
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md            # You are here
```

---

## ğŸš€ Quick Start

```bash
cd ssr-studio
pip install openai anthropic rich pytest

# Run the demo (requires API key)
python demo.py --api-key YOUR_OPENAI_KEY
```

See [ssr-studio/README.md](ssr-studio/README.md) for full documentation.

---

## ğŸ”¬ Key Innovation: 7-Step Validation

The SSR paper introduces rigorous validation for generated bugs:

| Step | Validation |
|------|------------|
| 1 | Test file exists |
| 2 | Code parses correctly |
| 3 | Original tests still pass |
| 4 | Bug is in allowed scope |
| 5 | Oracle test fails on buggy code |
| 6 | Oracle test passes on clean code |
| 7 | Inverse mutation testing |

This ensures every generated training example is meaningful.

---

## ğŸ“Š Research Applications

- **Training data generation** - Create unlimited bug/fix pairs
- **Model evaluation** - Compare LLM fixing capabilities  
- **Self-improvement** - Enable agents to generate their own curriculum
- **Benchmark creation** - Generate SWE-bench-style tasks

---

## ğŸ“„ Citation

```bibtex
@article{wei2024swerl,
  title={SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution},
  author={Wei, Yuxiang and Duchenne, Olivier and Copet, Jade and Carbonneaux, Quentin and Zhang, Lingming and Fried, Daniel and Synnaeve, Gabriel and Singh, Rishabh and Wang, Sida I.},
  journal={arXiv preprint arXiv:2512.18552},
  year={2024}
}
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.
